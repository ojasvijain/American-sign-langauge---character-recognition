{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('D:/Downloads/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "message = ' '\n",
    "frame_interval = 10\n",
    "frame_count = 0\n",
    "pred = []\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image(pil2tensor(img, dtype=np.float32).div_(255))\n",
    "    pred_class, pred_idx, outputs = learn.predict(img)\n",
    "    if (frame_count % frame_interval) == 0:\n",
    "        letter = max(set(pred), key=pred.count)\n",
    "        if letter == 'nothing':\n",
    "            pass\n",
    "        elif letter == 'space':\n",
    "            message += ' '\n",
    "        elif letter == 'del':\n",
    "            message = message[:-1]  \n",
    "        else:\n",
    "            message += letter\n",
    "        pred = []\n",
    "    else:\n",
    "        pred.append(str(pred_class))\n",
    "    cv2.putText(frame, str(pred_class)+' prob: '+str(outputs[pred_idx])[7:-1], (100, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, red, thickness=2, lineType=2)\n",
    "    cv2.putText(frame, message, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, green, thickness=2, lineType=2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYNNTPPPPYQQLPPWCBCQQCIISBO\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(set(pred), key=pred.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'N']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2085e-31, 3.8421e-25, 4.2002e-29, 1.5965e-34, 6.4472e-07, 7.3444e-31,\n",
       "        5.9175e-15, 1.4025e-23, 3.6465e-25, 2.5195e-32, 2.3788e-33, 3.0840e-12,\n",
       "        8.0138e-01, 4.1583e-12, 1.3005e-18, 6.7386e-15, 3.8266e-28, 1.9861e-01,\n",
       "        4.4475e-14, 2.9063e-25, 4.8465e-15, 4.0899e-07, 1.8948e-15, 1.1043e-24,\n",
       "        1.3162e-10, 2.4400e-27, 3.0386e-21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2085e-31, 3.8421e-25, 4.2002e-29, 1.5965e-34, 6.4472e-07, 7.3444e-31,\n",
       "        5.9175e-15, 1.4025e-23, 3.6465e-25, 2.5195e-32, 2.3788e-33, 3.0840e-12,\n",
       "        8.0138e-01, 4.1583e-12, 1.3005e-18, 6.7386e-15, 3.8266e-28, 1.9861e-01,\n",
       "        4.4475e-14, 2.9063e-25, 4.8465e-15, 4.0899e-07, 1.8948e-15, 1.1043e-24,\n",
       "        1.3162e-10, 2.4400e-27, 3.0386e-21])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8014)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8014)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ' '\n",
    "frame_interval = 10\n",
    "frame_count = 0\n",
    "pred = []\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    \n",
    "#     hand_cascade = cv2.CascadeClassifier('D:/College/Sem VI/CV/aGest.xml')\n",
    "#     hand_rect = hand_cascade.detectMultiScale(frame, scaleFactor = 1.2, minNeighbors = 5)\n",
    "#     for (x, y, w, h) in hand_rect: \n",
    "#         cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "#     cv2.imshow('crop', frame[y:y+h, x:x+w])\n",
    "#     frame[y:y+h, x:x+w]\n",
    "    \n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image(pil2tensor(img, dtype=np.float32).div_(255))\n",
    "    pred_class, pred_idx, outputs = learn.predict(img)\n",
    "    \n",
    "    if (frame_count % frame_interval) == 0:\n",
    "        letter = max(set(pred), key=pred.count)\n",
    "        if letter == 'nothing':\n",
    "            pass\n",
    "        elif letter == 'space':\n",
    "            message += ' '\n",
    "        elif letter == 'del':\n",
    "            message = message[:-1]  \n",
    "        else:\n",
    "            message += letter\n",
    "        pred = []\n",
    "    else:\n",
    "        pred.append(str(pred_class))\n",
    "    \n",
    "    cv2.putText(frame, str(pred_class)+' prob: '+str(outputs[pred_idx])[7:-1], (100, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, red, thickness=2, lineType=2)\n",
    "    cv2.putText(frame, message, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, green, thickness=2, lineType=2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = cv2.imread('D:/College/Sem VI/CV/download (2).jfif')\n",
    "cv2.imshow('orig', frame)\n",
    "hand_cascade = cv2.CascadeClassifier('D:/College/Sem VI/CV/haarcascade_frontalface_alt2.xml')\n",
    "hand_rect = hand_cascade.detectMultiScale(frame, scaleFactor=1.2, minNeighbors=5)\n",
    "for (x, y, w, h) in hand_rect: \n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "    cv2.imshow('crop', frame[y:y+h, x:x+w])\n",
    "cv2.imshow('detected', frame)\n",
    "cv2.waitKey()\n",
    "\n",
    "# frame[y:y+h, x:x+w]\n",
    "# if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14,  51, 156, 156]], dtype=int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CascadeClassifier 00000204A29D1990>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0000'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(outputs[pred_idx])[7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMIIXXXLLYYY\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
